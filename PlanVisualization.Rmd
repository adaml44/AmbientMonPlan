---
title: "PlanVisualization"
author: "Adam Bajo-Walker"
date: "`r Sys.Date()`"
output: html_document
---

```{r Setup, include = TRUE, warning = FALSE, message = FALSE}

library(tidyverse)
library(sf)
library(inlmisc)
library(leaflet)
library(leaflet.extras)
library(readxl)
library(viridis)

# only need this package if you are trying to connect to pinned data
library(pins)
```

This chunk will connect you to the DEQ R server to find pinned data. You will have to make sure you have a config file (with API server credentials) and is in the current working directory. You will also have to make sure you are routing through a secured DEQ network. If you do not have an API key and cannot connect to the server (or are not on a secure DEQ network/VPN) proceed to the next chunk. 

Another thing to keep in mind, the package 'pins' and the associated code below that accesses data through pins will not work unless you are using R version 3.6.2. All chunks below should work with different versions of R.

```{r Connect to Server, include = TRUE, warning = FALSE, message = FALSE}
# get configuration settings
conn <- config::get(file = 'PINSconfig.yml',
                    "connectionSettings")

# use API key to register board
board_register_rsconnect(key = conn$CONNECT_API_KEY,
                         server = conn$CONNECT_SERVER)

# viewing what pinned data are available 
pin_find(board = 'rsconnect') %>% 
  View()

# pulling station information
stations <- pin_get('ejones/WQM-Stations-Spatial', board = 'rsconnect')

# Water quality standards
WQS <- pin_get('ejones/WQSlookup-withStandards', board = 'rsconnect')

# filtering by BRRO stations; you can filter the stations data by any column but we are interested in stations that are only within the Blue Ridge Region
BRROstations <- filter(stations, ASSESS_REG == 'BRRO')

# all we are doing here is combining the Blue Ridge station info with the water quality standard info; this code combines the two data sets by using 'StationID' as the column to reference the two data sets
BRROstationsWQS <- left_join(BRROstations, WQS, by = 'StationID')

# how many BRRO stations have WQS attributed to them? More-or-less, how many stations don't have water quality data?
filter(BRROstationsWQS, !is.na(WQS_ID)) %>% 
  nrow()

# Lets save this data as .csv files so we can use it freely down the line
write.csv(BRROstations, 'Data/BRROstations.csv', na = '')
write.csv(stations, "Data/Stations.csv", na = '')

# We will also need the Virginia 6-digit HUC spatial layer to help with visuals
vahu6 <- st_as_sf(pin_get('ejones/vahu6', board = 'rsconnect'))
```


So, lets pull in the 2023-2024 sites we have identified for runs this year!
Remember to read in the correct excel file and the correct sheet! This code will leave out all of the other sheets within our excel file.

Keep in mind; this excel file was built using our (i.e., BRRO) traditional way of building monitoring plans: identifying sites for the year to be sampled for HF bacteria, AW, Trend, Lakes, PFAS, etc. So you should have your own file with sites you have identified to be sampled for the year. You will have to alter this code based on your files and associated column headers. 

```{r Pull in Working Data, include = TRUE, warning = FALSE, message = FALSE}
BRROsites23 <- read_excel('Data/BRRO_Monitoring_Plan_2023.xlsx',
                          sheet = 'Runs.23-24')

BRROsites23 <- BRROsites23 %>% 
  rename("2023" = "x2023",
         "2024" = "x2024",
         "Code" = "Prog Code")

# We have some rows of random numbers because of some calculations we were doing before
#     We can remove those rows with the following:

BRROsites23 <- BRROsites23[-c(175:190),]
```

Above, we had you pull station information from pinned data. If you were unable to do so, you will have to check out the 'Stations.csv' in the data folder to figure out what stations you will need. This file contains all stations for Virginia in CEDS, so it is a beast of a file!

```{r Pull in Stations, include = TRUE, warning = FALSE, message = FALSE}
# for example, if we want to filter the file for just the Piedmont Region we would filter using;
PROstations <- read.csv('Data/Stations.csv')%>%
  filter(ASSESS_REG == 'PRO')
```

And again, we had you pull in the Virginia 6-digit HUC spatial layer from pinned data, if you are unable to do so, you will have to read it in from the data folder.

```{r Pull in Watersheds, include = TRUE, warning = FALSE, message = FALSE}
vahu6 <- read_sf("Data/vahu6.shp")
```

Now we can begin to make our maps!

First things first, lets make a leaflet map with just our 6-digit HUC boundaries! It is a pretty decent sized shape-file, so it may take a minute to load!

```{r First Map, include = TRUE, warning = FALSE, message = FALSE}
CreateWebMap(maps = c("Topo","Imagery"), collapsed = TRUE) %>%
  addPolygons(data = vahu6,
              fillColor = 'blue', 
              opacity = 0.5, 
              weight = 1.5,
              layerId = ~VAHU6, 
              label = ~VAHU6, 
              group = 'Assessment Watersheds') %>% 
  addLayersControl(baseGroups=c("Topo",'Imagery'),
                   overlayGroups = c('Assessment Watersheds'),
                   options=layersControlOptions(collapsed=T),
                   position='topleft')
```


We can start to add a few things to this but also filtering to keep the size of the plot down. For us, we have different types of sites that we wanted to color code so I created a simple object called 'Stats' to house a list of colors to use. 

```{r}
Stats <- colorFactor(
  palette = viridis_pal(begin = 0.2, end = 0.90, option = 'H')(5),
  domain = BRROsites23$Code
)

CreateWebMap(maps = c("Topo", "Imagery"), collapsed = TRUE) %>%
  addPolygons(data = vahu6 %>% filter(ASSESS_REG == 'BRRO'), 
              color = 'blue',
              weight = 1.5,
              opacity = 0.5,
              highlightOptions = highlightOptions(color = "#FFF1BE",
                                                  weight = 5,
                                                  opacity = 1.0),
              layerId = ~VAHU6,
              label = ~VAHU6,
              group = 'Assessment Watersheds')%>%
  addCircleMarkers(data = BRROsites23,
                   stroke = F,
                   radius = 8,
                   fillColor = ~Stats(Code),
                   fillOpacity = 1,
                   layerId = ~`2023`,
                   label = ~`2023`,
                   group = 'Stations')%>%
  addLayersControl(baseGroups = c("Topo", "Imagery"),
                   overlayGroups = c('Assessment Watersheds', 'Stations'),
                   options = layersControlOptions(collapsed = T),
                   position = 'topleft')%>%
  addLegend(data = BRROsites23,
            pal = Stats,
            values = ~Code,
            title = "Ambient Run Code",
            opacity = 1)%>%
  inlmisc::AddSearchButton(group = "Stations", zoom = 15,
                           textPlaceholder = "Search stations")


```

So we now have our 2023 stations within our BRRO assessment region, lets create polygons based on our "runs" we have outlined in our monitoring plan.

```{r}
# changing our 2023 data table into a simple features table to create "geometries" from
BRROsites23 <- st_as_sf(BRROsites23, coords = c("Longitude", "Latitude"))

# All this code is doing is condensing our 2023 data table (which is now an sf object) into each run
#Should now have a single row for each run where all of our sites are condensed into the geometry column, if you plot 'BRRO23' you will get a whole bunch of points color-coded by run

# !!!!THIS IS A VERY DIRTY WAY OF CREATING POLYGONS FROM POINT DATA, I WOULD ADIVSE AGAINST USING THE 'BRRO23' DATAFRAME TO PLOT POINTS USEFULLY ON A MAP !!!!
BRRO23 = st_sf(
  aggregate(
    BRROsites23,
    by = list(ID = BRROsites23$Run),
    FUN = function(vals){vals[1]}
  )
)

# Take a look at how the "geometry" column plots
plot(BRRO23['ID'])

# Lets create a new SF object to create our actual polygons from
BRRORun23 <- BRRO23

# this code will change the geometry column from points to actual polygons
# st_convex_hull will join the points into the smallest geometry polygon
st_geometry(BRRORun23) <- st_convex_hull(BRRORun23$geometry)

# Lets plot it to see if the polygons make sense
plot(BRRORun23['ID'])


# we have 20 polygons here which matches up with our runs pretty well
# keep in mind BBAY23 contains only a single site and will not return a polygon in this instance so we can remove that row with the following:
BRRORun23 <- BRRORun23[-c(2),]


```

Lets make another map!

This time, we are going to take the previous map we made but add in the "runs" we have by plotting the polygons from the last step. 

```{r}
Stats <- colorFactor(
  palette = viridis_pal(begin = 0.2, end = 0.90, option = 'H')(5),
  domain = BRROsites23$Code
)

CreateWebMap(maps = c("Topo", "Imagery"), collapsed = TRUE) %>%
  addPolygons(data = vahu6 %>% filter(ASSESS_REG == 'BRRO'), 
              color = 'blue',
              weight = 1.5,
              opacity = 0.5,
              highlightOptions = highlightOptions(color = "#FFF1BE",
                                                  weight = 5,
                                                  opacity = 1.0),
              layerId = ~VAHU6,
              label = ~VAHU6,
              group = 'Assessment Watersheds')%>%
  addPolygons(data = BRRORun23,
              color = 'grey',
              weight = 1.5,
              opacity = 1.0,
              fillColor = ~BRRORun23$Color,
              fillOpacity = 0.6,
              highlightOptions = highlightOptions(color = "#FFF1BE",
                                                  weight = 5,
                                                  opacity = 1.0),
              layerId = ~ID,
              label = ~ID,
              group = 'BRRO Runs 2023')%>%
  addCircleMarkers(data = BRROsites23,
                   stroke = F,
                   radius = 8,
                   fillColor = ~Stats(Code),
                   fillOpacity = 1,
                   layerId = ~`2023`,
                   label = ~`2023`,
                   group = 'Stations')%>%
  addLayersControl(baseGroups = c("Topo", "Imagery"),
                   overlayGroups = c('Assessment Watersheds','BRRO Runs 2023',
                                     'Stations'),
                   options = layersControlOptions(collapsed = T),
                   position = 'topleft')%>%
  addLegend(data = BRROsites23,
            pal = Stats,
            values = ~Code,
            title = "Ambient Run Code",
            opacity = 1)%>%
  inlmisc::AddSearchButton(group = "Stations", zoom = 15,
                           textPlaceholder = "Search stations")


```
From here we can start to add in other types of field work like High Frequency Bacteria (HFB), or Lake runs 

```{r}
BRROHF23 <- read_excel('Data/BRRO_Monitoring_Plan_2023.xlsx', sheet = 'HFB.23')

Lakes23 <- read_excel('Data/BRRO_Monitoring_Plan_2023.xlsx', sheet = 'Lakes.23-24')

Lakes23 <- Lakes23[-c(51:60),]
```

Now we can combine everything together!

```{r}
Stats <- colorFactor(
  palette = viridis_pal(begin = 0.2, end = 0.90, option = 'H')(5),
  domain = BRROsites23$Code
)
z <- vahu6 %>% filter(ASSESS_REG == 'BRRO')

CreateWebMap(maps = c("Topo", "Imagery"), collapsed = TRUE) %>%
  addPolygons(data = z, 
              color = 'blue',
              weight = 1.5,
              opacity = 0.5,
              highlightOptions = highlightOptions(color = "#FFF1BE",
                                                  weight = 5,
                                                  opacity = 1.0),
              layerId = ~VAHU6,
              label = ~VAHU6,
              group = 'Assessment Watersheds',
              popup = paste0(z$VAHU6,
                             "<hr>",
                             z$VaName,
                             "<br>",
                             z$Basin))%>%
  addPolygons(data = BRRORun23,
              color = 'grey',
              weight = 1.5,
              opacity = 1.0,
              fillColor = ~BRRORun23$Color,
              fillOpacity = 0.6,
              highlightOptions = highlightOptions(color = "#FFF1BE",
                                                  weight = 5,
                                                  opacity = 1.0),
              layerId = ~ID,
              label = ~ID,
              group = 'BRRO Runs 2023',
              popup = paste0("<b>",
                             BRRORun23$ID))%>%
  addCircleMarkers(data = BRROsites23,
                   stroke = F,
                   radius = 8,
                   fillColor = ~Stats(Code),
                   fillOpacity = 1,
                   layerId = ~`2023`,
                   label = ~`2023`,
                   group = 'Stations')%>%
  addCircleMarkers(data = BRROHF23,
                   stroke = F,
                   radius = 8,
                   fillColor = ~BRROHF23$Color,
                   fillOpacity = 1.0,
                   layerId = ~StationID,
                   label = ~StationID,
                   group = 'HF Bacteria')%>%
  addMarkers(data = Lakes23,
             layerId = ~Station,
             label = ~Station,
             group = 'Lake Stations')%>%
  addLayersControl(baseGroups = c("Topo", "Imagery"),
                   overlayGroups = c('Assessment Watersheds','BRRO Runs 2023',
                                     'HF Bacteria','Lake Stations','Stations'),
                   options = layersControlOptions(collapsed = T),
                   position = 'topleft')%>%
  hideGroup('Assessment Watersheds')%>%
  hideGroup('HF Bacteria')%>%
  hideGroup('Lake Stations')%>%
  addLegend(data = BRROsites23,
            pal = Stats,
            values = ~Code,
            title = "Ambient Run Code",
            opacity = 1)%>%
  inlmisc::AddSearchButton(group = "Stations", zoom = 15,
                           textPlaceholder = "Search stations")

```

Disclaimer: Just realized that the assessment watershed pop-ups are not registering the correct information. I am working on figuring out why that is but defintiely confirm watershed information before making desicions or formal figures.
